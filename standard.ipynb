{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm\n",
    "from time import time\n",
    "import random\n",
    "from torchvision.transforms import ToTensor, ToPILImage\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cfg:\n",
    "    data_dir = '/opt/ml/DACON-PaperingFlawDetection/dataset'  \n",
    "    img_dir = f'{data_dir}/train'\n",
    "    df_path = f'{data_dir}/df.csv'\n",
    "\n",
    "df = pd.read_csv(cfg.df_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folder = glob(cfg.data_dir + '/train/*')\n",
    "\n",
    "train_path = []\n",
    "for folder in train_folder:\n",
    "    tmp = glob(folder + '/*')\n",
    "    train_path += tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/opt/ml/DACON-PaperingFlawDetection/dataset/tr...</td>\n",
       "      <td>피스</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/opt/ml/DACON-PaperingFlawDetection/dataset/tr...</td>\n",
       "      <td>피스</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/opt/ml/DACON-PaperingFlawDetection/dataset/tr...</td>\n",
       "      <td>피스</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/opt/ml/DACON-PaperingFlawDetection/dataset/tr...</td>\n",
       "      <td>피스</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/opt/ml/DACON-PaperingFlawDetection/dataset/tr...</td>\n",
       "      <td>피스</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3452</th>\n",
       "      <td>/opt/ml/DACON-PaperingFlawDetection/dataset/tr...</td>\n",
       "      <td>들뜸</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3453</th>\n",
       "      <td>/opt/ml/DACON-PaperingFlawDetection/dataset/tr...</td>\n",
       "      <td>들뜸</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3454</th>\n",
       "      <td>/opt/ml/DACON-PaperingFlawDetection/dataset/tr...</td>\n",
       "      <td>들뜸</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3455</th>\n",
       "      <td>/opt/ml/DACON-PaperingFlawDetection/dataset/tr...</td>\n",
       "      <td>들뜸</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3456</th>\n",
       "      <td>/opt/ml/DACON-PaperingFlawDetection/dataset/tr...</td>\n",
       "      <td>들뜸</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3457 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   path label\n",
       "0     /opt/ml/DACON-PaperingFlawDetection/dataset/tr...    피스\n",
       "1     /opt/ml/DACON-PaperingFlawDetection/dataset/tr...    피스\n",
       "2     /opt/ml/DACON-PaperingFlawDetection/dataset/tr...    피스\n",
       "3     /opt/ml/DACON-PaperingFlawDetection/dataset/tr...    피스\n",
       "4     /opt/ml/DACON-PaperingFlawDetection/dataset/tr...    피스\n",
       "...                                                 ...   ...\n",
       "3452  /opt/ml/DACON-PaperingFlawDetection/dataset/tr...    들뜸\n",
       "3453  /opt/ml/DACON-PaperingFlawDetection/dataset/tr...    들뜸\n",
       "3454  /opt/ml/DACON-PaperingFlawDetection/dataset/tr...    들뜸\n",
       "3455  /opt/ml/DACON-PaperingFlawDetection/dataset/tr...    들뜸\n",
       "3456  /opt/ml/DACON-PaperingFlawDetection/dataset/tr...    들뜸\n",
       "\n",
       "[3457 rows x 2 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.DataFrame(train_path, columns=['path'])\n",
    "train_df['label'] = train_df['path'].apply(lambda x: x.split('/')[-2])\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_info = dict(heights=[], widths=[], means=[], stds=[])\n",
    "\n",
    "for idx, i in enumerate(train_df.label.unique()):\n",
    "    df = train_df[train_df['label'] == i].reset_index(drop = True)\n",
    "    for k in range(0, len(df)-1) :\n",
    "        image_path = df.loc[k, 'path']\n",
    "        img = np.array(Image.open(image_path))\n",
    "        h, w, _ = img.shape\n",
    "        img_info['heights'].append(h)\n",
    "        img_info['widths'].append(w)\n",
    "        img_info['means'].append(img.mean(axis=(0,1)))\n",
    "        img_info['stds'].append(img.std(axis=(0,1)))\n",
    "        \n",
    "print(img_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average height for dataset is 626\n",
      "Minimum width for dataset is 357\n",
      "Maximum width for dataset is 1425\n",
      "Average width for dataset is 645\n",
      "RGB Mean: [0.60094771 0.59251739 0.57662358]\n",
      "RGB Standard Deviation: [0.08710572 0.09090757 0.09473773]\n"
     ]
    }
   ],
   "source": [
    "print(f'Average height for dataset is {int(np.mean(img_info[\"heights\"]))}')\n",
    "print(f'Minimum width for dataset is {np.min(img_info[\"widths\"])}')\n",
    "print(f'Maximum width for dataset is {np.max(img_info[\"widths\"])}')\n",
    "print(f'Average width for dataset is {int(np.mean(img_info[\"widths\"]))}')\n",
    "\n",
    "print(f'RGB Mean: {np.mean(img_info[\"means\"], axis=0) / 255.}')\n",
    "print(f'RGB Standard Deviation: {np.mean(img_info[\"stds\"], axis=0) / 255.}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
